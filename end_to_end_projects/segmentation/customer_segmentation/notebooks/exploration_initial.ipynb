{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data overview:\n",
    "- Size of the Data -- 200 rows and 5 features\n",
    "- Presence of Missing Data -- No\n",
    "- Scale Data? -- Yes\n",
    "- How data currently organised?\n",
    "    - The rows are initially sorted by increasing Annual income\n",
    "\n",
    "| Features | Detail of Feature | Actions to Take |\n",
    "| --- | --- | --- |\n",
    "| CustomerID | unique identification for each individual (int) | Remove (no duplicate records) |\n",
    "| Gender | gender of the individual (obj)-- male/female | One Hot Encoding |\n",
    "| Age | age of the individual (int) | scale this feature |\n",
    "| Annual Income (k$) | individual's annual income (int) | scale this feature |\n",
    "| Spending Score (1-100) | a metric on the value of a customer (int)| scale this feature |\n",
    "\n",
    "\n",
    "Personal choices:\n",
    "- Quality of life changes\n",
    "    - Changed the dataframe column headers to lowercase and without spaces\n",
    "- Scaling\n",
    "    - Release #1... with Min-max scaling (between 0 and 1).\n",
    "\n",
    "\n",
    "Modelling\n",
    "- General\n",
    "    - Release #1...the use of algorithms that partition the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def working_directory():\n",
    "    \"\"\"fixed the issue\n",
    "\n",
    "    Returns:\n",
    "        str: the location of the ideal directory\n",
    "    \"\"\"\n",
    "    return os.getcwd().replace(\"\\\\notebooks\",\"\")\n",
    "os.chdir(working_directory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import sys\n",
    "import multiprocessing\n",
    "\n",
    "# related third party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from pyclustertend import hopkins\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation, SpectralClustering\n",
    "import joblib\n",
    "\n",
    "# Local application/library specific imports\n",
    "#from src.config import RAW_DATA_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(RAW_DATA_FILE).set_index('CustomerID')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f30ea19e858dcd7cb4581bf637bde7f17ef7a9c49fa752d2b9dea102b005652"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('clusters 11L21': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
